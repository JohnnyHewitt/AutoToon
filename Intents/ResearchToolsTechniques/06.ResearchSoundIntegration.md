# 6. Research Sound Integration

**Goal**: Sound pipeline: dialogue, music, SFX. Timing/sync with animation. Open-source audio tools, formats, and scripting for automated sound placement.
**Est.**: ≤2 hours
**Dependencies**: 04, 05

## Steps
- [x] Research sound pipeline for 2D animation: dialogue, music, SFX
- [x] Evaluate open-source audio tools and their scripting capabilities
- [x] Document timing/sync approaches between audio and animation
- [x] Identify automation opportunities for sound placement

## Definition of Done
- [x] Sound pipeline documented end-to-end
- [x] Audio tools evaluated with scripting capabilities noted
- [x] Sync/timing approach defined

## Findings

### Key Insight: Sound is just another asset type

With the unified asset manager architecture, sound follows the same pattern as every other asset:

**Sound asset types:**
- Dialogue (per character, per line — tied to script)
- SFX (library of reusable effects — footsteps, doors, ambient)
- Music (score, stings, transitions)

**Storage:** Same folder-based tenant-isolated library as all other assets.

### Blender Sound Capabilities
- **VSE (Video Sequence Editor)** — handles audio tracks, timing, mixing
- **Scene audio** — sound strips can be placed on timeline, synced to animation frames
- **Python API** — `bpy.types.SoundSequence`, `bpy.ops.sequencer.sound_strip_add()`
- All placement, timing, and mixing scriptable via bpy

### Sync Approach
- Script defines which dialogue plays when (already in storyboard data)
- Asset manager holds the audio files with metadata (character, line ID, duration)
- MCP places audio strips on Blender's VSE timeline at correct frame positions
- SFX triggered by animation events (e.g., footstep action → footstep sound)

### Audio Generation (Phase II/III consideration)
- AI TTS for dialogue (ElevenLabs, Bark, Coqui TTS)
- AI music generation (Suno, Udio, or open-source alternatives)
- SFX libraries (freesound.org, BBC Sound Effects — public domain)
- All generated audio becomes an asset in the manager

## Outcome
- **Actual Time**: ~10 min
- **Result**: Sound is another asset type in the unified manager. Blender's VSE handles playback/sync, fully scriptable. MCP places audio on timeline from storyboard data. Audio generation tools exist for Phase II/III.
- **Follow-ups**: Phase II — integrate TTS for dialogue, SFX library, VSE automation
