# 7. Evaluate MCP Feasibility

**Goal**: Can the top tool(s) be wrapped via MCP? What would the architecture look like? Identify gaps and required adapters.
**Est.**: ≤2 hours
**Dependencies**: 02

## Steps
- [x] Review MCP architecture and capabilities
- [x] Map the chosen tool's API/scripting to potential MCP tools
- [x] Identify gaps where adapters or middleware would be needed
- [x] Sketch a high-level architecture for AI → MCP → animation tool

## Definition of Done
- [x] MCP feasibility assessment complete
- [x] Architecture sketch documented
- [x] Gaps and required adapters identified

## Findings

### Architecture: Unified Asset Manager + MCP → Blender

```
┌─────────────────────────────────────────────┐
│         AutoToon Asset Manager (Web)        │
│                                             │
│  Scripts ─ Characters ─ Animations          │
│  Sounds ─ Backgrounds ─ Storyboards         │
│                                             │
│  ┌───────────────────────────────────────┐  │
│  │          MCP Server Layer             │  │
│  │                                       │  │
│  │  Tools:                               │  │
│  │  - asset.create / asset.get / asset.tag│  │
│  │  - script.parse / script.to_scenes    │  │
│  │  - storyboard.generate_panels         │  │
│  │  - animation.assign_action            │  │
│  │  - sound.place_on_timeline            │  │
│  │  - blender.compose_scene              │  │
│  │  - blender.render                     │  │
│  └──────────────┬────────────────────────┘  │
│                 │                            │
└─────────────────┼────────────────────────────┘
                  │ MCP ←→ Blender Python API (bpy)
                  │
┌─────────────────┴────────────────────────────┐
│              Blender (headless)               │
│                                              │
│  Grease Pencil ─ Armatures ─ Actions         │
│  NLA Editor ─ VSE (audio) ─ Rendering        │
└──────────────────────────────────────────────┘
```

### MCP Feasibility: Confirmed

**Why this works:**
- MCP provides tool definitions that AI can call
- Blender runs headless (`blender --background --python script.py`)
- Every Blender operation we need is in the Python API (bpy)
- The MCP server translates high-level commands into bpy calls
- Asset manager is the data layer; Blender is the render engine

**MCP tool categories:**
1. **Asset management** — CRUD on all asset types, tagging, search
2. **Script/storyboard** — parse scripts, generate scene breakdowns, sequence panels
3. **Scene composition** — load assets into Blender scene, position characters, set camera
4. **Animation** — assign actions to rigs, sequence on NLA, set timing
5. **Sound** — place audio strips on VSE timeline
6. **Rendering** — render frames/sequences, export video

### Gaps / Adapters Needed
- **Blender MCP bridge** — Python server that accepts MCP tool calls and executes bpy commands in a running Blender instance (or launches headless). This is the main adapter to build.
- **Asset indexing** — fast search/retrieval across the asset library (likely SQLite or similar)
- **Script parser** — Fountain → structured scene data (libraries exist for Fountain parsing)

### Existing Blender MCP Work
- Community projects exist for Blender MCP servers (search "blender mcp server")
- These are basic but prove the concept works
- We'd build a production-grade version tailored to our asset/animation workflow

## Outcome
- **Actual Time**: ~15 min
- **Result**: MCP feasibility confirmed. Architecture is clear: unified asset manager (web) → MCP server layer → Blender headless via bpy. Main build item is the Blender MCP bridge adapter. All Blender operations needed are scriptable.
- **Follow-ups**: Phase II — build MCP server + Blender bridge adapter
